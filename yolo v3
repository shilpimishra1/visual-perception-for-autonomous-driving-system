from google.colab import drive
drive.mount('/content/drive')
# Install required libraries
!pip install opencv-python numpy


# Import libraries
import cv2
import numpy as np
from google.colab.patches import cv2_imshow
from IPython.display import display, Javascript
from google.colab.output import eval_js
from base64 import b64decode
import PIL.Image
import io


# Load YOLOv3 model
yolo = cv2.dnn.readNet("/content/drive/MyDrive/yolov3.weights", "/content/drive/MyDrive/yolov3 (1).cfg")


# Load COCO class labels
with open("/content/drive/MyDrive/coco.names", "r") as file:
    classes = [line.strip() for line in file.readlines()]


# Get output layers of the network
layer_names = yolo.getLayerNames()
output_layers = [layer_names[i - 1] for i in yolo.getUnconnectedOutLayers()]


# Define colors for bounding boxes
colorRed = (0, 0, 255)
colorGreen = (0, 255, 0)


# Function to capture image from webcam in Colab
def take_photo():
    js = """
    async function takePhoto() {
        const video = document.createElement('video');
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        document.body.appendChild(video);
        video.srcObject = stream;
        await new Promise((resolve) => video.onloadedmetadata = resolve);
        video.play();
        await new Promise((resolve) => setTimeout(resolve, 500));


        const canvas = document.createElement('canvas');
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        canvas.getContext('2d').drawImage(video, 0, 0);
        stream.getTracks().forEach(track => track.stop());
        document.body.removeChild(video);
        return canvas.toDataURL('image/jpeg');
    }
    takePhoto();
    """
    data = eval_js(js)
    binary = b64decode(data.split(',')[1])
    image = PIL.Image.open(io.BytesIO(binary))
    return np.array(image)


# Capture image from webcam
frame = take_photo()
height, width, channels = frame.shape


# Convert frame to YOLO format
blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)
yolo.setInput(blob)
outputs = yolo.forward(output_layers)


# Initialize lists for detected objects
class_ids = []
confidences = []
boxes = []


# Process YOLO outputs
for output in outputs:
    for detection in output:
        scores = detection[5:]
        class_id = np.argmax(scores)
        confidence = scores[class_id]


        if confidence > 0.5:
            # Get object coordinates
            center_x = int(detection[0] * width)
            center_y = int(detection[1] * height)
            w = int(detection[2] * width)
            h = int(detection[3] * height)


            x = int(center_x - w / 2)
            y = int(center_y - h / 2)


            boxes.append([x, y, w, h])
            confidences.append(float(confidence))
            class_ids.append(class_id)


# Perform Non-Maximum Suppression (NMS) to filter overlapping boxes
indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)


# Draw bounding boxes and labels
if len(indexes) > 0:
    for i in indexes.flatten():
        x, y, w, h = boxes[i]
        label = str(classes[class_ids[i]])
        confidence_text = f"{label} {confidences[i]:.2f}"


        cv2.rectangle(frame, (x, y), (x + w, y + h), colorGreen, 3)
        cv2.putText(frame, confidence_text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, colorRed, 2)


# Display the output image
cv2_imshow(frame)


